import os
import sys
import time
import json
import numpy as np
from dotenv import load_dotenv

# --------------------------
# 0. í™˜ê²½ ì„¤ì • ë° ê²½ë¡œ ì„¸íŒ…
# --------------------------
load_dotenv()

# rag_api ëª¨ë“ˆ importë¥¼ ìœ„í•´ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), "rag_api"))

from rag_api.rag_chatbot import FineTunedEmbedder, FAISSRetriever
from openai import OpenAI

# í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜
EMBEDDING_MODEL_PATH = os.getenv("EMBEDDING_MODEL_PATH")
FAISS_INDEX_PATH = os.getenv("FAISS_INDEX_PATH")
METADATA_JSON_PATH = os.getenv("METADATA_JSON_PATH")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

EVAL_FILE = "eval_dataset.jsonl"
TOP_K = 5

if not OPENAI_API_KEY:
    print("âŒ OPENAI_API_KEY ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .envë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")
    sys.exit(1)

client = OpenAI(api_key=OPENAI_API_KEY)

print("\n======================================================================")
print("ğŸ¤– PYXIS RAG CHATBOT â€” ENTERPRISE LEVEL PERFORMANCE REPORT")
print("======================================================================")
print(f"ğŸ“‚ ì„ë² ë”© ëª¨ë¸ ê²½ë¡œ: {EMBEDDING_MODEL_PATH}")
print(f"ğŸ“‚ FAISS ì¸ë±ìŠ¤ ê²½ë¡œ: {FAISS_INDEX_PATH}")
print(f"ğŸ“‚ ë©”íƒ€ë°ì´í„° ê²½ë¡œ: {METADATA_JSON_PATH}")
print("======================================================================\n")


# --------------------------
# 1. ì„ë² ë”© & FAISS ë¡œë”©
# --------------------------
embedder = FineTunedEmbedder(model_path=EMBEDDING_MODEL_PATH)
retriever = FAISSRetriever(
    index_path=FAISS_INDEX_PATH,
    metadata_path=METADATA_JSON_PATH,
    embedder=embedder
)


# --------------------------
# 2. í‰ê°€ìš© ì»¨í…ìŠ¤íŠ¸ & ë‹µë³€ ìƒì„± ë¡œì§
#    (ì„œë¹„ìŠ¤ìš© í”„ë¡¬í”„íŠ¸ì™€ ì™„ì „íˆ ë¶„ë¦¬!)
# --------------------------
def build_eval_context(docs, max_len_chars: int = 1500) -> str:
    """í‰ê°€ìš©ìœ¼ë¡œ ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë‹¨ìˆœí•˜ê²Œ í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±"""
    parts = []
    for i, doc in enumerate(docs, 1):
        title = doc.get("title", "ì œëª© ì—†ìŒ")
        content = doc.get("content", doc.get("text", "")) or ""
        snippet = content[:max_len_chars]
        parts.append(f"[ë¬¸ì„œ {i}] ì œëª©: {title}\në‚´ìš©: {snippet}")
    return "\n\n".join(parts)


def generate_eval_answer(question: str, docs) -> str:
    """
    í‰ê°€ ì „ìš© LLM í˜¸ì¶œ.
    - ì´ëª¨ì§€, ë§í¬, ì¡°ì–¸ ì—†ì´
    - ë”± í•œ ë¬¸ì¥ìœ¼ë¡œë§Œ ì •ì±… í•µì‹¬ì„ ë§í•˜ê²Œ í•¨
    """
    context = build_eval_context(docs)
    if not context.strip():
        return "ì œê³µëœ ë¬¸ì„œë§Œìœ¼ë¡œëŠ” ë‹µë³€í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤."

    messages = [
        {
            "role": "system",
            "content": (
                "ë„ˆëŠ” ëŒ€í•œë¯¼êµ­ ì¤‘ì†Œê¸°ì—… ì§€ì›ì •ì±…ì„ ì˜ ì•„ëŠ” ì „ë¬¸ ìƒë‹´ì‚¬ì•¼. "
                "ë°˜ë“œì‹œ ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ë§Œ ì‚¬ìš©í•´ì„œ ì‚¬ì‹¤ë§Œ ì •í™•í•˜ê²Œ ë§í•´. "
                "ë‹µë³€ì€ ë”± í•œ ë¬¸ì¥, ì¡´ëŒ“ë§, ë¶ˆí•„ìš”í•œ ì„¤ëª…Â·ì´ëª¨ì§€Â·ë§í¬Â·ëª©ë¡ ì—†ì´ "
                "ì •ì±…ì˜ í•µì‹¬ ì •ë³´(ì§€ì› ëŒ€ìƒ, ì§€ì› ë‚´ìš©, ê¸°ê°„ ë“±)ë§Œ ë§í•´."
            ),
        },
        {
            "role": "user",
            "content": (
                "ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•´ì„œ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë‹µì„ í•œ ë¬¸ì¥ìœ¼ë¡œë§Œ ì¨ ì£¼ì„¸ìš”.\n\n"
                f"ì§ˆë¬¸: {question}\n\n"
                f"[ë¬¸ì„œ]\n{context}"
            ),
        },
    ]

    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        temperature=0.0,
        max_tokens=256,
    )
    return resp.choices[0].message.content.strip()


# --------------------------
# 3. Retrieval Hit Rate@K
# --------------------------
def compute_hit_rate() -> float:
    total, hit = 0, 0
    with open(EVAL_FILE, "r", encoding="utf-8") as f:
        for line in f:
            if not line.strip():
                continue
            item = json.loads(line)
            q = item["question"]
            gold = item["gold_doc_id"]

            res = retriever.search(q, top_k=TOP_K)
            retrieved_ids = [r["id"] for r in res]

            if gold in retrieved_ids:
                hit += 1
            total += 1
    return hit / total if total > 0 else 0.0


# --------------------------
# 4. GPT-Judge Answer Accuracy
# --------------------------
def gpt_judge_accuracy() -> float:
    total, correct = 0, 0

    with open(EVAL_FILE, "r", encoding="utf-8") as f:
        for line in f:
            if not line.strip():
                continue
            item = json.loads(line)
            q = item["question"]
            gold = item["gold_answer"]

            # 1) ê²€ìƒ‰ & í‰ê°€ìš© ë‹µë³€ ìƒì„±
            retrieved = retriever.search(q, top_k=TOP_K)
            bot_answer = generate_eval_answer(q, retrieved)

            # 2) GPTì—ê²Œ "ì •ë‹µ/ì˜¤ë‹µ" íŒì • ìš”ì²­
            judge_messages = [
                {
                    "role": "system",
                    "content": (
                        "ë„ˆëŠ” ì±„ì ê´€ì´ì•¼. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ "
                        "ëª¨ë¸ ë‹µë³€ì´ GOLD ì •ë‹µê³¼ ì˜ë¯¸ì ìœ¼ë¡œ ê°™ì€ì§€ í‰ê°€í•´. "
                        "ëœ»ì´ ê±°ì˜ ê°™ìœ¼ë©´ 1, ë‹¤ë¥´ë©´ 0ë§Œ ìˆ«ìë¡œ ì¶œë ¥í•´."
                    ),
                },
                {
                    "role": "user",
                    "content": (
                        f"ì§ˆë¬¸: {q}\n\n"
                        f"GOLD ì •ë‹µ: {gold}\n\n"
                        f"ëª¨ë¸ ë‹µë³€: {bot_answer}\n\n"
                        "ì •ë‹µì´ë©´ 1, ì˜¤ë‹µì´ë©´ 0ë§Œ ì¶œë ¥í•´."
                    ),
                },
            ]

            judgment = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=judge_messages,
                temperature=0.0,
                max_tokens=4,
            )

            content = judgment.choices[0].message.content.strip()
            try:
                score = int(content[0])
            except Exception:
                score = 0

            correct += 1 if score == 1 else 0
            total += 1

    return correct / total if total > 0 else 0.0


# --------------------------
# 5. Hallucination Rate
#    (ë¬¸ì„œ ê·¼ê±° ë°–ì˜ ì •ë³´ ë¹„ìœ¨)
# --------------------------
def hallucination_rate() -> float:
    total, hallucinated = 0, 0

    with open(EVAL_FILE, "r", encoding="utf-8") as f:
        for line in f:
            if not line.strip():
                continue
            item = json.loads(line)
            q = item["question"]

            retrieved = retriever.search(q, top_k=TOP_K)
            bot_answer = generate_eval_answer(q, retrieved)
            context = build_eval_context(retrieved)

            judge_messages = [
                {
                    "role": "system",
                    "content": (
                        "ë„ˆëŠ” ì‚¬ì‹¤ ê²€ì¦ ì „ë¬¸ê°€ì•¼. ëª¨ë¸ ë‹µë³€ì´ ì•„ë˜ ë¬¸ì„œ ë‚´ìš©ì— ê·¼ê±°í–ˆëŠ”ì§€ í‰ê°€í•´. "
                        "ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì´ë‚˜ ì™œê³¡ëœ ì‚¬ì‹¤ì´ ë“¤ì–´ê°€ë©´ 1, "
                        "ë¬¸ì„œì— ìˆëŠ” ë‚´ìš©ìœ¼ë¡œë§Œ ë‹µí–ˆìœ¼ë©´ 0ë§Œ ìˆ«ìë¡œ ì¶œë ¥í•´."
                    ),
                },
                {
                    "role": "user",
                    "content": (
                        f"[ë¬¸ì„œ]\n{context}\n\n"
                        f"[ëª¨ë¸ ë‹µë³€]\n{bot_answer}\n\n"
                        "ê·¼ê±° ì—†ëŠ” ë‚´ìš©(í™˜ê°)ì´ ìˆìœ¼ë©´ 1, ì—†ìœ¼ë©´ 0ë§Œ ì¶œë ¥í•´."
                    ),
                },
            ]

            judgment = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=judge_messages,
                temperature=0.0,
                max_tokens=4,
            )

            content = judgment.choices[0].message.content.strip()
            try:
                score = int(content[0])
            except Exception:
                score = 1  # ì• ë§¤í•˜ë©´ í™˜ê°ìœ¼ë¡œ ì²˜ë¦¬

            hallucinated += 1 if score == 1 else 0
            total += 1

    return hallucinated / total if total > 0 else 0.0


# --------------------------
# 6. Latency (ì‘ë‹µ ì†ë„)
# --------------------------
def response_latency():
    times = []

    with open(EVAL_FILE, "r", encoding="utf-8") as f:
        for line in f:
            if not line.strip():
                continue
            item = json.loads(line)
            q = item["question"]

            start = time.time()
            retrieved = retriever.search(q, top_k=TOP_K)
            _ = generate_eval_answer(q, retrieved)
            end = time.time()

            times.append(end - start)

    if not times:
        return 0.0, 0.0

    avg = float(np.mean(times))
    p95 = float(np.percentile(times, 95))
    return avg, p95


# --------------------------
# 7. Index Coverage
# --------------------------
def index_coverage() -> int:
    return len(retriever.metadata)


# --------------------------
# 8. ë©”íŠ¸ë¦­ ì „ì²´ ì‹¤í–‰
# --------------------------
if __name__ == "__main__":
    hit_rate = compute_hit_rate()
    acc = gpt_judge_accuracy()
    halluc = hallucination_rate()
    avg_lat, p95_lat = response_latency()
    coverage = index_coverage()

    print("ğŸ“Œ ENTERPRISE PERFORMANCE REPORT\n")
    print(f"ğŸ” Retrieval Hit Rate@{TOP_K}: {hit_rate:.3f}")
    print(f"ğŸ§  GPT-Judge Answer Accuracy: {acc:.3f}")
    print(f"âš ï¸ Hallucination Rate: {halluc:.3f}")
    print(f"âš¡ Average Latency: {avg_lat:.3f} sec")
    print(f"â±ï¸  P95 Latency: {p95_lat:.3f} sec")
    print(f"ğŸ“š Index Coverage: {coverage} documents")

    print("\n======================================================================")
    print("ğŸ“ˆ Pyxis ì±—ë´‡ â€” Enterprise-grade AI Performance Evaluation Completed")
    print("======================================================================\n")
