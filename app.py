import os
import json
import faiss
import numpy as np
import openai
from fastapi import FastAPI
from pydantic import BaseModel
from sentence_transformers import SentenceTransformer
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv
from typing import List, Optional

# ğŸ” í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# ğŸ“ ê²½ë¡œ ì„¤ì •
INDEX_PATH = "./faiss_index.index"
METADATA_PATH = "./metadata.json"

# ğŸ¤– ëª¨ë¸ ë¡œë”©
model = SentenceTransformer("all-MiniLM-L6-v2")
faiss_index = faiss.read_index(INDEX_PATH)

with open(METADATA_PATH, encoding='utf-8') as f:
    metadata = json.load(f)

# ğŸš€ FastAPI ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
app = FastAPI()

# ğŸŒ CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# âœ… ë°ì´í„° ëª¨ë¸ ì •ì˜
class UserInfo(BaseModel):
    loginId: str
    nickname: str

class ChatHistory(BaseModel):
    role: str  # "user" or "assistant"
    content: str

class ChatRequest(BaseModel):
    user: UserInfo
    query: str
    sessionHistory: Optional[List[ChatHistory]] = []

class SourceData(BaseModel):
    title: str
    source: str
    url: str
    snippet: str

class ChatResponse(BaseModel):
    sourceData: List[SourceData]
    botResponse: str
    followUpQuestions: Optional[List[str]] = []

# ğŸ§ª ìƒíƒœ í™•ì¸
@app.get("/")
def root():
    return {"message": "âœ… ì •ì±… ì±—ë´‡ API ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤."}

# ğŸ“® ë©”ì¸ ì§ˆë¬¸ API
@app.post("/api/v1/query", response_model=ChatResponse)
async def query_endpoint(req: ChatRequest):
    query = req.query
    q_vec = model.encode(query).astype("float32").reshape(1, -1)

    # ğŸ” ë²¡í„° ê²€ìƒ‰
    k = 3
    distances, indices = faiss_index.search(q_vec, k)

    # ğŸ“š ê´€ë ¨ ë¬¸ì„œ ìˆ˜ì§‘
    source_data = []
    retrieved_chunks = []
    seen_titles = set()

    for idx in indices[0]:
        doc = metadata[idx]
        title = doc.get("title", "ì•Œ ìˆ˜ ì—†ìŒ")
        source = doc.get("source", "ì •ì±…ìë£Œ")
        url = doc.get("url", "")
        snippet = doc.get("text", "")[:200]  # ì•ë¶€ë¶„ë§Œ ë³´ì—¬ì¤Œ
        if title not in seen_titles:
            source_data.append(SourceData(title=title, source=source, url=url, snippet=snippet))
            seen_titles.add(title)
        retrieved_chunks.append(doc.get("text", ""))

    # ğŸ§  GPT ìš”ì²­ êµ¬ì„±
    context_text = "\n\n".join(retrieved_chunks)
    gpt_messages = [
        {"role": "system", "content": "ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ì •í™•í•˜ê²Œ ë‹µí•´ì£¼ì„¸ìš”. ë§ˆì§€ë§‰ì—ëŠ” ì¶”ì²œ í›„ì† ì§ˆë¬¸ 2ê°œë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”."}
    ]
    if req.sessionHistory:
        gpt_messages.extend([sh.dict() for sh in req.sessionHistory])
    gpt_messages.append({
        "role": "user",
        "content": f"ë¬¸ì„œ:\n{context_text}\n\nì§ˆë¬¸: {query}"
    })

    # ğŸ¯ GPT í˜¸ì¶œ
    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=gpt_messages
        )
        full_response = response.choices[0].message.content.strip()

        # í›„ì† ì§ˆë¬¸ ì¶”ì¶œ
        if "í›„ì† ì§ˆë¬¸" in full_response:
            bot_text, *follow = full_response.split("í›„ì† ì§ˆë¬¸")
            follow_questions = [q.strip("-â€¢ \n") for q in follow[0].split("\n") if q.strip()]
        else:
            bot_text = full_response
            follow_questions = []

    except Exception as e:
        bot_text = f"âŒ GPT ì˜¤ë¥˜: {str(e)}"
        follow_questions = []

    return ChatResponse(
        sourceData=source_data,
        botResponse=bot_text,
        followUpQuestions=follow_questions
    )
