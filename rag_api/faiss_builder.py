#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë¹„ì¦ˆì¸í¬ ì •ì±… ë°ì´í„° FAISS ë²¡í„° ì¸ë±ìŠ¤ êµ¬ì¶• ìŠ¤í¬ë¦½íŠ¸
- ê° ì •ì±… í´ë”ì˜ extracted.txtë¥¼ ì½ì–´ ì„ë² ë”© ìƒì„±
- BAAI/bge-m3 ëª¨ë¸ ì‚¬ìš© (íŒŒì¸íŠœë‹ ë²„ì „)
- FAISS ì¸ë±ìŠ¤ ë° ë©”íƒ€ë°ì´í„° JSON ì €ì¥
"""

import os
import json
import re
from pathlib import Path
from typing import List, Dict, Tuple
import torch
from transformers import AutoTokenizer, AutoModel
import faiss
import numpy as np
from tqdm import tqdm

class PolicyVectorBuilder:
    def __init__(self, base_path: str, model_name: str = "BAAI/bge-m3"):
        """
        Args:
            base_path: bizinfo_data í´ë” ê²½ë¡œ
            model_name: ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸
        """
        self.base_path = Path(base_path).expanduser()
        self.model_name = model_name
        
        # GPU ì‚¬ìš© ì„¤ì •
        if torch.cuda.is_available():
            self.device = torch.device('cuda')
            print(f"ğŸŸ¢ GPU ì‚¬ìš©: {torch.cuda.get_device_name(0)}")
        else:
            self.device = torch.device("cpu")
            print("âš ï¸ GPU ì‚¬ìš© ë¶ˆê°€ â†’ CPUë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")

        print(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {self.device}")
        print(f"ğŸ® GPU: {torch.cuda.get_device_name(0)}")
        print(f"ğŸ’¾ GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        print(f"ğŸ“‚ ë°ì´í„° ê²½ë¡œ: {self.base_path}")
        
        # ëª¨ë¸ ë¡œë“œ
        print(f"ğŸ“¥ ëª¨ë¸ ë¡œë”© ì¤‘: {model_name}")
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModel.from_pretrained(
            model_name,
            use_safetensors=True,
            trust_remote_code=True
        ).to(self.device)
        self.model.eval()
        
        # GPU ìµœì í™” ì„¤ì •
        if hasattr(torch.cuda, 'amp'):
            print("âš¡ Mixed Precision (FP16) í™œì„±í™”")
            self.use_amp = True
        else:
            self.use_amp = False
        
        print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        
        self.policies = []
        self.metadata = []
        self.embeddings_cache = {}  # ì„ë² ë”© ìºì‹œ
    
    def load_existing_metadata(self, metadata_path: Path):
        """ê¸°ì¡´ ë©”íƒ€ë°ì´í„° ë¡œë“œí•˜ì—¬ ìºì‹œ êµ¬ì¶•"""
        if metadata_path.exists():
            print(f"ğŸ“¥ ê¸°ì¡´ ë©”íƒ€ë°ì´í„° ë¡œë”©: {metadata_path}")
            try:
                with open(metadata_path, 'r', encoding='utf-8') as f:
                    existing_metadata = json.load(f)
                
                # ê¸°ì¡´ ë°ì´í„°ë¥¼ ìºì‹œì— ì €ì¥
                for idx, meta in enumerate(existing_metadata):
                    cache_key = f"{meta['id']}_{meta['title']}"
                    self.embeddings_cache[cache_key] = {
                        'index': idx,
                        'metadata': meta
                    }
                
                print(f"âœ… {len(existing_metadata)}ê°œ ê¸°ì¡´ ì •ì±… ìºì‹œ ë¡œë“œ ì™„ë£Œ")
                return existing_metadata
            except Exception as e:
                print(f"âš ï¸  ë©”íƒ€ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
                return []
        return []
    
    def extract_folder_info(self, folder_name: str) -> Tuple[str, str]:
        """
        í´ë”ëª…ì—ì„œ IDì™€ ì œëª© ì¶”ì¶œ
        ì˜ˆ: [PBLN_000000000123456]íƒ„ì†Œì €ê°ì„ ìœ„í•œ... 
        -> id: PBLN_000000000123456, title: íƒ„ì†Œì €ê°ì„ ìœ„í•œ...
        """
        pattern = r'\[([^\]]+)\](.+)'
        match = re.match(pattern, folder_name)
        
        if match:
            policy_id = match.group(1)
            title = match.group(2).strip()
            return policy_id, title
        else:
            return None, None
    
    def scan_policies(self, skip_cached=True):
        """ëª¨ë“  ì •ì±… í´ë”ë¥¼ ìŠ¤ìº”í•˜ì—¬ extracted.txt íŒŒì¼ ì°¾ê¸°"""
        print("\nğŸ” ì •ì±… í´ë” ìŠ¤ìº” ì¤‘...")
        
        if not self.base_path.exists():
            raise FileNotFoundError(f"ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.base_path}")
        
        policy_folders = [d for d in self.base_path.iterdir() if d.is_dir()]
        print(f"ğŸ“ ì´ {len(policy_folders)}ê°œ í´ë” ë°œê²¬")
        
        found_count = 0
        skipped_count = 0
        cached_count = 0
        
        for folder in tqdm(policy_folders, desc="í´ë” ìŠ¤ìº”"):
            policy_id, title = self.extract_folder_info(folder.name)
            
            if not policy_id or not title:
                skipped_count += 1
                continue
            
            # ìºì‹œ ì²´í¬
            cache_key = f"{policy_id}_{title}"
            if skip_cached and cache_key in self.embeddings_cache:
                cached_count += 1
                continue
            
            extracted_file = folder / "extracted.txt"
            
            if not extracted_file.exists():
                skipped_count += 1
                continue
            
            # íŒŒì¼ ì½ê¸°
            try:
                with open(extracted_file, 'r', encoding='utf-8') as f:
                    content = f.read().strip()
                
                if not content:
                    skipped_count += 1
                    continue
                
                # ë©”íƒ€ë°ì´í„° êµ¬ì¡° ìˆ˜ì •
                self.policies.append({
                    'title': title,
                    'id': policy_id,
                    'content': content,  # ë³¸ë¬¸ ì „ì²´
                    'source': str(extracted_file)  # filepath â†’ sourceë¡œ ë³€ê²½
                })
                found_count += 1
                
            except Exception as e:
                print(f"âš ï¸  {folder.name} ì½ê¸° ì‹¤íŒ¨: {e}")
                skipped_count += 1
                continue
        
        print(f"\nâœ… ìƒˆë¡œ ë°œê²¬: {found_count}ê°œ")
        print(f"â™»ï¸  ìºì‹œë¨: {cached_count}ê°œ")
        print(f"â­ï¸  ìŠ¤í‚µ: {skipped_count}ê°œ")
        print(f"ğŸ“Š ì´ ì²˜ë¦¬ ëŒ€ìƒ: {len(self.policies)}ê°œ ì •ì±…")
    
    @torch.no_grad()
    def generate_embedding(self, text: str) -> np.ndarray:
        """í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜ (CLS í† í° ì‚¬ìš©, GPU ìµœì í™”)"""
        # í† í°í™” (ê¸´ í…ìŠ¤íŠ¸ëŠ” ì•ë¶€ë¶„ë§Œ ì‚¬ìš©)
        inputs = self.tokenizer(
            text,
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=8192  # bge-m3ëŠ” ìµœëŒ€ 8192 í† í° ì§€ì›
        ).to(self.device)
        
        # GPU Mixed Precision ì‚¬ìš© (ë” ë¹ ë¥¸ ì²˜ë¦¬)
        if self.use_amp:
            with torch.cuda.amp.autocast():
                outputs = self.model(**inputs)
        else:
            outputs = self.model(**inputs)
        
        # CLS í† í° ì‚¬ìš© (bge-m3 ê¶Œì¥ ë°©ì‹)
        embeddings = outputs.last_hidden_state[:, 0]
        
        # ì •ê·œí™”
        embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)
        
        return embeddings.cpu().numpy()[0]
    
    def build_faiss_index(self, output_dir: str = None, use_gpu_index: bool = True):
        """FAISS ì¸ë±ìŠ¤ êµ¬ì¶• (ê¸°ì¡´ ì„ë² ë”© ì¬ì‚¬ìš©, GPU ê°€ì†)"""
        if output_dir is None:
            output_dir = self.base_path.parent
        else:
            output_dir = Path(output_dir)
        
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ê¸°ì¡´ ì¸ë±ìŠ¤ì™€ ë©”íƒ€ë°ì´í„° ë¡œë“œ
        index_path = output_dir / "policy_faiss.index"
        metadata_path = output_dir / "metadata.json"
        
        existing_embeddings = []
        existing_metadata = self.load_existing_metadata(metadata_path)
        
        if index_path.exists() and existing_metadata:
            print(f"ğŸ“¥ ê¸°ì¡´ FAISS ì¸ë±ìŠ¤ ë¡œë”©: {index_path}")
            try:
                existing_index = faiss.read_index(str(index_path))
                # GPU ì¸ë±ìŠ¤ì¸ ê²½ìš° CPUë¡œ ì´ë™
                if hasattr(existing_index, 'getDevice'):
                    existing_index = faiss.index_gpu_to_cpu(existing_index)
                # ê¸°ì¡´ ì„ë² ë”©ì„ numpy ë°°ì—´ë¡œ ë³µì›
                existing_embeddings = np.array([
                    existing_index.reconstruct(i) 
                    for i in range(existing_index.ntotal)
                ]).astype('float32')
                print(f"âœ… {len(existing_embeddings)}ê°œ ê¸°ì¡´ ì„ë² ë”© ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸  ê¸°ì¡´ ì¸ë±ìŠ¤ ë¡œë”© ì‹¤íŒ¨: {e}")
                existing_embeddings = []
                existing_metadata = []
        
        # ìƒˆë¡œìš´ ì •ì±…ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ ì„ë² ë”© ìƒì„±
        new_embeddings = []
        if self.policies:
            print(f"\nğŸ§® ìƒˆë¡œìš´ {len(self.policies)}ê°œ ì •ì±… ì„ë² ë”© ìƒì„± ì¤‘ (GPU ê°€ì†)...")
            
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            torch.cuda.empty_cache()
            
            for policy in tqdm(self.policies, desc="ì„ë² ë”© ìƒì„±"):
                # content ë³¸ë¬¸ì„ ì„ë² ë”©
                embedding = self.generate_embedding(policy['content'])
                new_embeddings.append(embedding)
                
                # ë©”íƒ€ë°ì´í„° ì €ì¥ (4ê°œ í•„ë“œë§Œ)
                existing_metadata.append({
                    'title': policy['title'],
                    'id': policy['id'],
                    'content': policy['content'],  # ë³¸ë¬¸ ì „ì²´ í¬í•¨
                    'source': policy['source']  # extracted.txt ê²½ë¡œ
                })
            
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            torch.cuda.empty_cache()
        
        # ê¸°ì¡´ + ìƒˆë¡œìš´ ì„ë² ë”© ê²°í•©
        if len(existing_embeddings) > 0:
            if len(new_embeddings) > 0:
                new_embeddings_array = np.array(new_embeddings).astype('float32')
                embeddings_array = np.vstack([existing_embeddings, new_embeddings_array])
                print(f"\nğŸ“Š ê¸°ì¡´ {len(existing_embeddings)}ê°œ + ì‹ ê·œ {len(new_embeddings)}ê°œ = ì´ {len(embeddings_array)}ê°œ")
                print(f"ğŸ“Š ìµœì¢… ë°°ì—´ Dtype: {embeddings_array.dtype}")
            else:
                embeddings_array = existing_embeddings
                print(f"\nğŸ“Š ê¸°ì¡´ ì„ë² ë”©ë§Œ ì‚¬ìš©: {len(embeddings_array)}ê°œ")
        else:
            if len(new_embeddings) > 0:
                embeddings_array = np.array(new_embeddings).astype('float32')
                print(f"\nğŸ“Š ìƒˆë¡œìš´ ì„ë² ë”©ë§Œ ìƒì„±: {len(embeddings_array)}ê°œ")
            else:
                raise ValueError("ì²˜ë¦¬í•  ì •ì±…ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        self.metadata = existing_metadata
        dimension = embeddings_array.shape[1]

        print(f"ğŸ“ ì„ë² ë”© ì°¨ì›: {dimension}")
        
        print(f"ğŸ“ ì„ë² ë”© ì°¨ì›: {dimension}")
        print(f"ğŸ“Š ì´ ë²¡í„° ê°œìˆ˜: {len(embeddings_array)}")
        
        # FAISS ì¸ë±ìŠ¤ ìƒì„± (Inner Product = Cosine Similarity)
        print("\nğŸ”¨ FAISS ì¸ë±ìŠ¤ êµ¬ì¶• ì¤‘...")
        cpu_index = faiss.IndexFlatIP(dimension)
        cpu_index.add(embeddings_array)
        
        # GPU ì¸ë±ìŠ¤ë¡œ ë³€í™˜ (ì„ íƒì‚¬í•­)
        save_index = cpu_index
        print(f"âœ… CPU ì¸ë±ìŠ¤ì— {cpu_index.ntotal}ê°œ ë²¡í„° ì¶”ê°€ë¨")
        
        # ì €ì¥
        print(f"\nğŸ’¾ ì €ì¥ ì¤‘...")
        faiss.write_index(save_index, str(index_path))
        print(f"âœ… FAISS ì¸ë±ìŠ¤ ì €ì¥: {index_path}")
        
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(self.metadata, f, ensure_ascii=False, indent=2)
        print(f"âœ… ë©”íƒ€ë°ì´í„° ì €ì¥: {metadata_path}")
        
        # ë©”íƒ€ë°ì´í„° êµ¬ì¡° í™•ì¸ ì¶œë ¥
        if self.metadata:
            print(f"\nğŸ“‹ ë©”íƒ€ë°ì´í„° ìƒ˜í”Œ (ì²« ë²ˆì§¸ í•­ëª©):")
            print("-" * 60)
            sample = self.metadata[0]
            print(f"  title: {sample['title'][:50]}...")
            print(f"  id: {sample['id']}")
            print(f"  content: {sample['content'][:100]}...")
            print(f"  source: {sample['source']}")
            print("-" * 60)
        
        # í†µê³„ ì¶œë ¥
        print("\n" + "="*60)
        print("ğŸ“Š êµ¬ì¶• ì™„ë£Œ í†µê³„")
        print("="*60)
        print(f"ì´ ì •ì±… ìˆ˜: {len(self.metadata)}")
        print(f"ì„ë² ë”© ì°¨ì›: {dimension}")
        print(f"ì‹ ê·œ ì¶”ê°€: {len(new_embeddings)}ê°œ")
        print(f"GPU ê°€ì†: {'âœ… ì‚¬ìš©' if use_gpu_index else 'âŒ ë¯¸ì‚¬ìš©'}")
        print(f"ì¸ë±ìŠ¤ íŒŒì¼: {index_path}")
        print(f"ë©”íƒ€ë°ì´í„° íŒŒì¼: {metadata_path}")
        print("\në©”íƒ€ë°ì´í„° í•„ë“œ:")
        print("  1. title (ì œëª©)")
        print("  2. id (ì •ì±… ID)")
        print("  3. content (ë³¸ë¬¸ ì „ì²´)")
        print("  4. source (extracted.txt ê²½ë¡œ)")
        print("="*60)
        
        return index_path, metadata_path
    
    def test_search(self, query: str, k: int = 5, sort_by: str = 'similarity', use_gpu: bool = True):
        """
        í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ ìˆ˜í–‰ (GPU ê°€ì†)
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            k: ë°˜í™˜í•  ê²°ê³¼ ê°œìˆ˜
            sort_by: ì •ë ¬ ê¸°ì¤€ ('similarity', 'id', 'title')
            use_gpu: GPU ì‚¬ìš© ì—¬ë¶€
        """
        if not self.metadata:
            print("âš ï¸  ë©”íƒ€ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. build_faiss_index()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            return
        
        print(f"\nğŸ” í…ŒìŠ¤íŠ¸ ê²€ìƒ‰: '{query}'")
        
        # ì¿¼ë¦¬ ì„ë² ë”©
        query_embedding = self.generate_embedding(query)
        query_embedding = np.array([query_embedding]).astype('float32')
        
        # ì¸ë±ìŠ¤ ë¡œë“œ
        output_dir = self.base_path.parent
        index_path = output_dir / "policy_faiss.index"
        cpu_index = faiss.read_index(str(index_path))
        
        # GPU ì¸ë±ìŠ¤ë¡œ ë³€í™˜ (ì„ íƒì‚¬í•­)
        index = cpu_index
        
        # ê²€ìƒ‰ (ë” ë§ì€ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¨ í›„ ì •ë ¬)
        search_k = max(k * 2, 20)  # ì •ë ¬ì„ ìœ„í•´ ë” ë§ì´ ê°€ì ¸ì˜´
        distances, indices = index.search(query_embedding, min(search_k, len(self.metadata)))
        
        # ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        results = []
        for distance, idx in zip(distances[0], indices[0]):
            if idx < len(self.metadata):
                meta = self.metadata[idx]
                results.append({
                    'similarity': float(distance),
                    'id': meta['id'],
                    'title': meta['title'],
                    'content': meta['content'][:200] + "...",  # ë¯¸ë¦¬ë³´ê¸°
                    'source': meta['source']
                })
        
        # ì •ë ¬
        if sort_by == 'similarity':
            results.sort(key=lambda x: x['similarity'], reverse=True)
        elif sort_by == 'id':
            results.sort(key=lambda x: x['id'])
        elif sort_by == 'title':
            results.sort(key=lambda x: x['title'])
        
        # ìƒìœ„ kê°œë§Œ ì„ íƒ
        results = results[:k]
        
        print(f"\nğŸ“‹ ìƒìœ„ {k}ê°œ ê²€ìƒ‰ ê²°ê³¼ (ì •ë ¬: {sort_by}, GPU: {'âœ…' if use_gpu else 'âŒ'}):")
        print("-" * 80)
        
        for rank, result in enumerate(results, 1):
            print(f"\n{rank}. [{result['id']}]")
            print(f"   ì œëª©: {result['title']}")
            print(f"   ìœ ì‚¬ë„: {result['similarity']:.4f}")
            print(f"   ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸°: {result['content']}")
            print(f"   ì¶œì²˜: {result['source']}")
        
        print("-" * 80)
        
        return results


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # âš ï¸ ì—¬ê¸°ë¥¼ ë³¸ì¸ì˜ ë°”íƒ•í™”ë©´ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”
    # Windows ì˜ˆì‹œ: "C:/Users/YourName/Desktop/bizinfo_data"
    # Mac/Linux ì˜ˆì‹œ: "~/Desktop/bizinfo_data"
    
    BASE_PATH = "C:\\Users\\user\\Desktop\\bizinfo_data"  # ğŸ‘ˆ ì´ ë¶€ë¶„ì„ ìˆ˜ì •í•˜ì„¸ìš”!
    MODEL_PATH = "C:\\Users\\user\\Desktop\\bge-m3-sft"  # ğŸ‘ˆ íŒŒì¸íŠœë‹ ëª¨ë¸ ê²½ë¡œ
    
    try:
        # ë¹Œë” ì´ˆê¸°í™”
        builder = PolicyVectorBuilder(
            base_path=BASE_PATH,
            model_name=MODEL_PATH
        )
        
        # ì •ì±… ìŠ¤ìº”
        builder.scan_policies()
        
        # FAISS ì¸ë±ìŠ¤ êµ¬ì¶•
        index_path, metadata_path = builder.build_faiss_index()
        
        # í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ (ì„ íƒì‚¬í•­)
        print("\n" + "="*60)
        print("ğŸ§ª í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ ì‹¤í–‰")
        print("="*60)
        
        test_queries = [
            "ì¤‘ì†Œê¸°ì—… ê¸°ìˆ ê°œë°œ ì§€ì›",
            "ìŠ¤íƒ€íŠ¸ì—… ì°½ì—… ìê¸ˆ",
            "ìˆ˜ì¶œ ì§€ì› ì‚¬ì—…"
        ]
        
        # ìœ ì‚¬ë„ ìˆœ ê²€ìƒ‰
        for query in test_queries:
            builder.test_search(query, k=3, sort_by='similarity')
            print()
        
        # ID ìˆœ ì •ë ¬ ì˜ˆì‹œ
        print("\n" + "="*60)
        print("ğŸ“Œ ID ìˆœ ì •ë ¬ ì˜ˆì‹œ")
        print("="*60)
        builder.test_search("ê¸°ìˆ ê°œë°œ", k=5, sort_by='id')
        
        # ì œëª© ìˆœ ì •ë ¬ ì˜ˆì‹œ
        print("\n" + "="*60)
        print("ğŸ“Œ ì œëª© ìˆœ ì •ë ¬ ì˜ˆì‹œ")
        print("="*60)
        builder.test_search("ì§€ì›ì‚¬ì—…", k=5, sort_by='title')
        
        print("\nğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()